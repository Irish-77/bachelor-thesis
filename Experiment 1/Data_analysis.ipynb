{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPfbR+prOJAH0wt7pkqFz/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uoj_xgnVW22C","executionInfo":{"status":"ok","timestamp":1649790338584,"user_tz":-120,"elapsed":2169,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"0414714c-0c87-44e4-b625-f071f93476fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","source":["!mkdir /usr/lib/python3.7/metrics\n","!cp -R /content/drive/MyDrive/BA/Notebooks/2_Experiment/review_object_detection_metrics-main/src /usr/lib/python3.7/metrics/src"],"metadata":{"id":"y7LqCIsa-jeR","executionInfo":{"status":"ok","timestamp":1649762951148,"user_tz":-120,"elapsed":11577,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install PyQt5\n","!pip install -qU torch_snippets"],"metadata":{"id":"V13dii7K-rdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649762977348,"user_tz":-120,"elapsed":22561,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"9816ca0f-b763-4e5c-da61-03394e6ea280"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyQt5\n","  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n","\u001b[K     |████████████████████████████████| 8.3 MB 12.8 MB/s \n","\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n","  Downloading PyQt5_sip-12.9.1-cp37-cp37m-manylinux1_x86_64.whl (338 kB)\n","\u001b[K     |████████████████████████████████| 338 kB 61.4 MB/s \n","\u001b[?25hCollecting PyQt5-Qt5>=5.15.2\n","  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n","\u001b[K     |████████████████████████████████| 59.9 MB 1.2 MB/s \n","\u001b[?25hInstalling collected packages: PyQt5-sip, PyQt5-Qt5, PyQt5\n","Successfully installed PyQt5-5.15.6 PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.1\n","\u001b[K     |████████████████████████████████| 45 kB 1.9 MB/s \n","\u001b[K     |████████████████████████████████| 948 kB 30.2 MB/s \n","\u001b[K     |████████████████████████████████| 10.9 MB 59.4 MB/s \n","\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n","\u001b[K     |████████████████████████████████| 60 kB 6.4 MB/s \n","\u001b[K     |████████████████████████████████| 229 kB 70.6 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 5.5 MB/s \n","\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n"]}]},{"cell_type":"code","source":["import copy\n","import glob\n","import torch\n","import time\n","import statistics\n","import pandas as pd\n","import numpy as np\n","\n","from IPython import display\n","from torch_snippets import *\n","from os.path import join\n","from PIL import Image\n","from metrics.src.bounding_box import BoundingBox\n","from metrics.src.evaluators import coco_evaluator, pascal_voc_evaluator\n","from metrics.src.bounding_box import BoundingBox\n","from metrics.src.utils.enumerators import BBFormat, BBType, CoordinatesType, MethodAveragePrecision\n","from skimage import data\n","from skimage.color import rgb2hsv, rgb2luv, rgb2lab"],"metadata":{"id":"5ahDrtKXXYPa","executionInfo":{"status":"ok","timestamp":1649768124272,"user_tz":-120,"elapsed":341,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/BA/dataset/Experimente/df_80_20_train_tf.csv')"],"metadata":{"id":"h-PFcvU8Xpg-","executionInfo":{"status":"ok","timestamp":1649763079196,"user_tz":-120,"elapsed":1631,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df_train.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"N3S6w0bkZHJF","executionInfo":{"status":"ok","timestamp":1649763079197,"user_tz":-120,"elapsed":8,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"cd99775f-0066-41b1-b757-9c5c64ef64eb"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               filename  class      xmin     xmax      ymin      ymax\n","0  0000599864fd15b3.jpg    Bus  0.343750  0.90875  0.156162  0.650047\n","1  00006bdb1eb5cd74.jpg  Truck  0.276667  0.69750  0.141604  0.437343"],"text/html":["\n","  <div id=\"df-ba68a4b2-7a76-4f62-86c5-fb7f31292ed0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>class</th>\n","      <th>xmin</th>\n","      <th>xmax</th>\n","      <th>ymin</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000599864fd15b3.jpg</td>\n","      <td>Bus</td>\n","      <td>0.343750</td>\n","      <td>0.90875</td>\n","      <td>0.156162</td>\n","      <td>0.650047</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00006bdb1eb5cd74.jpg</td>\n","      <td>Truck</td>\n","      <td>0.276667</td>\n","      <td>0.69750</td>\n","      <td>0.141604</td>\n","      <td>0.437343</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba68a4b2-7a76-4f62-86c5-fb7f31292ed0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ba68a4b2-7a76-4f62-86c5-fb7f31292ed0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ba68a4b2-7a76-4f62-86c5-fb7f31292ed0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["width, height = 300, 300\n","IMAGE_ROOT = '/content/drive/MyDrive/BA/dataset/bus-trucks/images'\n","\n","label2target = {l:t+1 for t,l in enumerate(df_train['class'].unique())}\n","label2target['background'] = 0\n","target2label = {t:l for l,t in label2target.items()}\n","label2target = {v: k for k, v in target2label.items()}\n","background_class = label2target['background']\n","num_classes = len(label2target)\n","\n","\n","def preprocess_image(img):\n","  img = torch.tensor(img).permute(2,0,1)\n","  return img.to(device).float()\n","\n","class OpenDataset(torch.utils.data.Dataset):\n","  w, h = width, height\n","  def __init__(self, df, image_dir=IMAGE_ROOT):\n","    self.image_dir = image_dir\n","    self.files = glob.glob(self.image_dir+'/*')\n","    self.df = df\n","    self.image_infos = df['filename'].unique()\n","\n","  def __getitem__(self, ix):\n","\n","    #filename\tclass\txmin\txmax\tymin\tymax\n","\n","    # # load images and masks\n","    image_id = self.image_infos[ix]\n","    img_path = find(image_id, self.files)\n","    img = Image.open(img_path).convert('RGB')\n","    img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n","\n","    data = self.df[self.df['filename'] == image_id]\n","    labels = data['class'].values.tolist()\n","    data = data[['xmin','ymin','xmax','ymax']].values\n","    data[:,[0,2]] *= self.w\n","    data[:,[1,3]] *= self.h\n","    boxes = data.astype(np.uint32).tolist() # convert to absolute coordinates\n","    # torch FRCNN expects ground truths as a dictionary of tensors\n","    target = {}\n","    target[\"boxes\"] = torch.Tensor(boxes).float()\n","    target[\"labels\"] = torch.Tensor([label2target[i] for i in labels]).long()\n","    img = preprocess_image(img)\n","\n","    return img, target\n","\n","  def collate_fn(self, batch):\n","    return tuple(zip(*batch)) \n","\n","  def __len__(self):\n","    return len(self.image_infos)"],"metadata":{"id":"kSi5tsq08kKz","executionInfo":{"status":"ok","timestamp":1649763104103,"user_tz":-120,"elapsed":295,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df_train = df_train[:150]"],"metadata":{"id":"Y_bUUxb1jhW8","executionInfo":{"status":"ok","timestamp":1649763319076,"user_tz":-120,"elapsed":381,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_ds = OpenDataset(df_train)\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=1, collate_fn=train_ds.collate_fn, drop_last=True)"],"metadata":{"id":"Zin2qn7V8nqW","executionInfo":{"status":"ok","timestamp":1649763322397,"user_tz":-120,"elapsed":424,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Average Object size"],"metadata":{"id":"8Ag7UlYgi5Zx"}},{"cell_type":"code","source":["bounding_boxes_train = []\n","\n","for ix, (images, targets) in enumerate(train_loader):\n","    #Ground Truth\n","  for i, box in enumerate(targets[0]['boxes']):\n","    cls = target2label[int(targets[0]['labels'][i])]\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    bounding_boxes_train.append(bb)\n","  if ix % 20 == 0:\n","    p = ix / len(train_loader)\n","    print(p, end = '\\r')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"au-zq9Sh_H6O","executionInfo":{"status":"ok","timestamp":1649763360139,"user_tz":-120,"elapsed":35817,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"fe5fe267-bb7d-4fd8-e5ee-3c70961ce395"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":[""]}]},{"cell_type":"code","source":["areas = []\n","for bbs in bounding_boxes_train:\n","  areas.append(bbs.get_area())"],"metadata":{"id":"iRcdw68k_zsc","executionInfo":{"status":"ok","timestamp":1649763436976,"user_tz":-120,"elapsed":308,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","import numpy as np\n","import math\n","\n","kmeans = KMeans(n_clusters=3, random_state=0).fit(np.array(areas).reshape(-1, 1))"],"metadata":{"id":"EMPbNITP_0xS","executionInfo":{"status":"ok","timestamp":1649763439708,"user_tz":-120,"elapsed":300,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["x = np.linspace(min(areas), max(areas), 100000)\n","preds = kmeans.predict(x.reshape(-1, 1))"],"metadata":{"id":"B-LE8D0Z_2Am","executionInfo":{"status":"ok","timestamp":1649763441670,"user_tz":-120,"elapsed":370,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["changes = np.where(preds[:-1] != preds[1:])[0]\n","print('Object boundaries for S and L sized objects', np.sqrt(x[changes]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e8mUlTg_23D","executionInfo":{"status":"ok","timestamp":1649763444066,"user_tz":-120,"elapsed":1,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"916bc052-a701-44db-ca45-53599c9d6caf"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Object boundaries for S and L sized objects [144.80688123 232.3492006 ]\n"]}]},{"cell_type":"code","source":["def image_light(img, thrshld = 127):\n","  rgb = img.cpu().permute(1,2,0) * 255\n","  rgb = np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n","  \n","  is_light = np.mean(rgb) > thrshld\n","\n","  # Light: 0\n","  # Dark: 1\n","\n","  # return 0 if is_light else 1\n","  return {'value': np.mean(rgb),\n","          'brightness': 'light' if is_light else 'dark'\n","          }\n","\n","def avg_img_color(img):\n","  rgb_avg = img.permute(1,2,0).mean(axis=(0, 1)) \n","  hsv_avg = rgb2hsv(img.permute(1,2,0)).mean(axis=(0, 1))\n","  luv_avg = rgb2luv(img.permute(1,2,0)).mean(axis=(0, 1))\n","  lab_avg = rgb2lab(img.permute(1,2,0)).mean(axis=(0, 1))\n","\n","  return {\n","    'rgb_avg_r': float(rgb_avg[0]),\n","    'rgb_avg_g': float(rgb_avg[1]),\n","    'rgb_avg_b': float(rgb_avg[2]),\n","    'hsv_avg_h': float(hsv_avg[0]),\n","    'hsv_avg_s': float(hsv_avg[1]),\n","    'hsv_avg_v': float(hsv_avg[2])\n","  }"],"metadata":{"id":"jV1tpztDEldR","executionInfo":{"status":"ok","timestamp":1649775048550,"user_tz":-120,"elapsed":383,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["def bb_intersection_over_union(boxA, boxB):\n","\n","  xA = max(boxA[0], boxB[0])\n","  yA = max(boxA[1], boxB[1])\n","  xB = min(boxA[2], boxB[2])\n","  yB = min(boxA[3], boxB[3])\n","\n","  interArea = (xB - xA) * (yB - yA)\n","\n","  boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n","  boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n","\n","  iou = interArea / float(boxAArea + boxBArea - interArea)\n","\n","  return iou\n","\n","\n","def detected(gt, detection, iou_threshold ):\n","\n","  for i, g in enumerate(gt):\n","    if g[0] == detection[0]:\n","      if g[1] == detection[1]:\n","        iuo = bb_intersection_over_union(g[-4:], detection[-4:])\n","        if iuo >= iou_threshold:\n","          return True\n","\n","  return False"],"metadata":{"id":"FPoEm7-cTN43","executionInfo":{"status":"ok","timestamp":1649796134792,"user_tz":-120,"elapsed":308,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["\n","metadata = []\n","\n","for ix, (images, targets) in enumerate(train_loader):\n","  img = images[0]\n","  t = targets[0]['boxes']\n","\n","  c_img = image_light(img)\n","  c_avg_img = avg_img_color(img)\n","\n","  gts = []\n","  for i, box in enumerate(targets[0]['boxes']):\n","    cls = target2label[int(targets[0]['labels'][i])]\n","    X1, Y1, X2, Y2 = box.tolist()\n","    gts.append((ix, cls, 1, X1, Y1, X2, Y2))\n","\n","  for i, box in enumerate(targets[0]['boxes']):\n","    cls = target2label[int(targets[0]['labels'][i])]\n","\n","    X1, Y1, X2, Y2 = box.numpy().astype(int)\n","\n","    # object frame\n","    obj_frame = img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det = detected(\n","        gts,\n","        [ix, cls, 1, X1, Y1, X2, Y2],\n","        0.1\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                   'image_brightness_value': c_img['value'],\n","                   'image_brightness_interpretation': c_img['brightness'],\n","                   'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                   'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                   'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                   'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                   'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                   'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                   'object_brightness_value': c_obj['value'],\n","                   'object_brightness_interpretation': c_obj['brightness'],\n","                   'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                   'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                   'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                   'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                   'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                   'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                   'detected': det,\n","                   'object_size': bb.get_area(),\n","                   'object_class': cls\n","                   }\n","                  )\n","    break"],"metadata":{"id":"xPAG6YRtEQyb","executionInfo":{"status":"ok","timestamp":1649796144981,"user_tz":-120,"elapsed":7965,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame.from_dict(metadata)\n","df.tail()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"YQixds1hHYun","executionInfo":{"status":"error","timestamp":1649833769877,"user_tz":-120,"elapsed":303,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"1a0b1080-b1ae-4a94-fa73-0d24bff7f982"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2920d29d5ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":["print('Image average brightness value', df['image_brightness_value'].mean())\n","print('Image std. brightness value', df['image_brightness_value'].std())\n","# print('Image average dark', len(df[df['brightness'] == 'dark']) / len(df))\n","# print('Image average light', len(df[df['brightness'] == 'light']) / len(df))\n","print('Object average brightness value', df['object_brightness_value'].mean())\n","print('Object std. brightness value', df['object_brightness_value'].std())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGMMpjhFH87m","executionInfo":{"status":"ok","timestamp":1649790349566,"user_tz":-120,"elapsed":440,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"7d929edc-4f85-4cad-892d-f8bc3f6bc9dd"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Image average brightness value 120.74817606027413\n","Image std. brightness value 22.478238773891274\n","Object average brightness value 103.76224241800544\n","Object std. brightness value 25.549411450476665\n"]}]},{"cell_type":"markdown","source":["Objekte sind durchschnittlich dunkler"],"metadata":{"id":"KXtf5XyjZiZM"}}]}