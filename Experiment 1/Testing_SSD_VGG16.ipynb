{"cells":[{"cell_type":"markdown","metadata":{"id":"Ymf05TlF5QAU"},"source":["# Main Configs"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zHVD0it245SC","executionInfo":{"status":"ok","timestamp":1650355532374,"user_tz":-120,"elapsed":266,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"outputs":[],"source":["small_df = False\n","batch_size = 1\n","width, height = 300, 300"]},{"cell_type":"markdown","metadata":{"id":"4BC8oFZjyN_v"},"source":["# Setup and Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16800,"status":"ok","timestamp":1650355552870,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"L07xyJhpDajY","outputId":"6e0f793a-9e2b-49d2-a7d6-17bc1cdebbad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11898,"status":"ok","timestamp":1650355564765,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"e_ov9EndF-XS"},"outputs":[],"source":["!mkdir /usr/lib/python3.7/metrics\n","!cp -R /content/drive/MyDrive/BA/Notebooks/2_Experiment/review_object_detection_metrics-main/src /usr/lib/python3.7/metrics/src"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wo1xjbFjNOvW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650355584261,"user_tz":-120,"elapsed":19503,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"44c7aa55-d13b-4c3d-da7f-52b64be0eaf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyQt5\n","  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n","\u001b[K     |████████████████████████████████| 8.3 MB 9.9 MB/s \n","\u001b[?25hCollecting PyQt5-Qt5>=5.15.2\n","  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n","\u001b[K     |████████████████████████████████| 59.9 MB 222 kB/s \n","\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n","  Downloading PyQt5_sip-12.10.1-cp37-cp37m-manylinux1_x86_64.whl (338 kB)\n","\u001b[K     |████████████████████████████████| 338 kB 51.9 MB/s \n","\u001b[?25hInstalling collected packages: PyQt5-sip, PyQt5-Qt5, PyQt5\n","Successfully installed PyQt5-5.15.6 PyQt5-Qt5-5.15.2 PyQt5-sip-12.10.1\n","\u001b[K     |████████████████████████████████| 48 kB 3.0 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n","\u001b[K     |████████████████████████████████| 10.9 MB 58.1 MB/s \n","\u001b[K     |████████████████████████████████| 948 kB 47.1 MB/s \n","\u001b[K     |████████████████████████████████| 229 kB 53.0 MB/s \n","\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n","\u001b[K     |████████████████████████████████| 60 kB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n","\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n"]}],"source":["!pip install PyQt5\n","!pip install -qU torch_snippets"]},{"cell_type":"code","source":["!git clone https://github.com/sizhky/ssd-utils/\n","%cd ssd-utils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-oHSKQ6UdYe","executionInfo":{"status":"ok","timestamp":1650355585178,"user_tz":-120,"elapsed":921,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"8437348c-9be1-414f-9894-137c5d825ad6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ssd-utils'...\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (9/9), done.\n","/content/ssd-utils\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XJigMscbLLYm","executionInfo":{"status":"ok","timestamp":1650355596931,"user_tz":-120,"elapsed":11754,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"outputs":[],"source":["import copy\n","import glob\n","import torch\n","import time\n","import statistics\n","import cv2\n","import pandas as pd\n","import IPython\n","\n","from os.path import join\n","from torch_snippets import *\n","from torchvision.ops import nms\n","import torchvision.ops.boxes as bops\n","from PIL import Image\n","from metrics.src.evaluators import coco_evaluator, pascal_voc_evaluator\n","from metrics.src.bounding_box import BoundingBox\n","from metrics.src.utils.enumerators import BBFormat, BBType, CoordinatesType, MethodAveragePrecision\n","from skimage import data\n","from skimage.color import rgb2hsv, rgb2luv, rgb2lab\n","from skimage.util import random_noise"]},{"cell_type":"code","source":["def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n","    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n","    filledLength = int(length * iteration // total)\n","    bar = fill * filledLength + '-' * (length - filledLength)\n","    string = f'\\r{prefix} |{bar}| {percent}% {suffix}'\n","    out.update(IPython.display.Pretty(string))\n","    # Print New Line on Complete\n","    if iteration == total: \n","        print()"],"metadata":{"id":"mJscJD3NAs40","executionInfo":{"status":"ok","timestamp":1650355597178,"user_tz":-120,"elapsed":15,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)"],"metadata":{"id":"TO7waIEJ2mpO","executionInfo":{"status":"ok","timestamp":1650355597179,"user_tz":-120,"elapsed":14,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tbSWaqcrXVJA","executionInfo":{"status":"ok","timestamp":1650355597180,"user_tz":-120,"elapsed":14,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"outputs":[],"source":["IMAGE_ROOT = '/content/drive/MyDrive/BA/dataset/bus-trucks/images'\n","OUTPUT_REPORTS = '/content/drive/MyDrive/BA/Notebooks/2_Experiment/Output_Reports'\n","OUTPUT_MODELS = '/content/drive/MyDrive/BA/Notebooks/2_Experiment/Output_Models'\n","output_training_report = 'ssd_vgg16.csv'\n","output_testing_report = 'testing_ssd_vgg16.xlsx'\n","output_model_name = 'ssd_vgg16.pt'"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2701,"status":"ok","timestamp":1650355599869,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"8K9USH1CGFjf","outputId":"ea378f1c-554e-4a55-cb54-a7ecb4ecb805"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               filename  class      xmin      xmax      ymin      ymax\n","0  00013f14dd4e168f.jpg    Bus  0.287500  0.999375  0.194184  0.999062\n","1  0002914fa805e227.jpg  Truck  0.061250  0.966875  0.125399  0.974495\n","2  0005f203463a13a8.jpg  Truck  0.000000  0.700000  0.187778  0.998889\n","3  00066517f9d814f9.jpg  Truck  0.000000  0.588867  0.069892  0.998208\n","4  000812dcf304a8e7.jpg    Bus  0.059375  0.848750  0.029936  0.958660"],"text/html":["\n","  <div id=\"df-a934db8a-e3dc-44d7-925c-6b93f9394495\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>class</th>\n","      <th>xmin</th>\n","      <th>xmax</th>\n","      <th>ymin</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00013f14dd4e168f.jpg</td>\n","      <td>Bus</td>\n","      <td>0.287500</td>\n","      <td>0.999375</td>\n","      <td>0.194184</td>\n","      <td>0.999062</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002914fa805e227.jpg</td>\n","      <td>Truck</td>\n","      <td>0.061250</td>\n","      <td>0.966875</td>\n","      <td>0.125399</td>\n","      <td>0.974495</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0005f203463a13a8.jpg</td>\n","      <td>Truck</td>\n","      <td>0.000000</td>\n","      <td>0.700000</td>\n","      <td>0.187778</td>\n","      <td>0.998889</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00066517f9d814f9.jpg</td>\n","      <td>Truck</td>\n","      <td>0.000000</td>\n","      <td>0.588867</td>\n","      <td>0.069892</td>\n","      <td>0.998208</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000812dcf304a8e7.jpg</td>\n","      <td>Bus</td>\n","      <td>0.059375</td>\n","      <td>0.848750</td>\n","      <td>0.029936</td>\n","      <td>0.958660</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a934db8a-e3dc-44d7-925c-6b93f9394495')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a934db8a-e3dc-44d7-925c-6b93f9394495 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a934db8a-e3dc-44d7-925c-6b93f9394495');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["df_train = pd.read_csv('/content/drive/MyDrive/BA/dataset/Experimente/df_80_20_train_tf.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/BA/dataset/Experimente/df_80_20_test_tf.csv')\n","df_test.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1650355614815,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"2wq9qa5eLQ1A","outputId":"79e4e654-9dd5-45fa-cc47-e773cdec767a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{1: 'Bus', 2: 'Truck', 0: 'background'}\n"]}],"source":["label2target = {l:t+1 for t,l in enumerate(df_train['class'].unique())}\n","label2target['background'] = 0\n","target2label = {t:l for l,t in label2target.items()}\n","label2target = {v: k for k, v in target2label.items()}\n","background_class = label2target['background']\n","num_classes = len(label2target)\n","\n","print(target2label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":858,"status":"ok","timestamp":1650296422042,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"oR_KeMMcCq8j","outputId":"3b2e5566-443a-487b-975a-c216f0f6d393"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   epoch      time       loss\n","0      0  0.557357  17.273149\n","1      0  0.271990  15.240695\n","2      0  0.279001  13.537352\n","3      0  0.313096  11.247987\n","4      0  0.267380   9.465345"],"text/html":["\n","  <div id=\"df-7e0ce0fa-dd43-4735-98c2-e8fdb2b09279\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>epoch</th>\n","      <th>time</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.557357</td>\n","      <td>17.273149</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.271990</td>\n","      <td>15.240695</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.279001</td>\n","      <td>13.537352</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.313096</td>\n","      <td>11.247987</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.267380</td>\n","      <td>9.465345</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e0ce0fa-dd43-4735-98c2-e8fdb2b09279')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7e0ce0fa-dd43-4735-98c2-e8fdb2b09279 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7e0ce0fa-dd43-4735-98c2-e8fdb2b09279');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["df_report = pd.read_csv(join(OUTPUT_REPORTS, output_training_report))\n","df_report.head()"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"vkZ4WrSFVUWF","executionInfo":{"status":"ok","timestamp":1650355616716,"user_tz":-120,"elapsed":232,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from torchvision import transforms\n","\n","def preprocess_image(img):\n","  img = torch.tensor(img).permute(2,0,1)\n","  return img.to(device).float()\n","\n","normalize = transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406],\n","    std=[0.229, 0.224, 0.225]\n",")\n","denormalize = transforms.Normalize(\n","    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n","    std=[1/0.229, 1/0.224, 1/0.255]\n",")"],"metadata":{"id":"nPggY6lIUDaq","executionInfo":{"status":"ok","timestamp":1650355617319,"user_tz":-120,"elapsed":2,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Q2ryFbUNs85q","executionInfo":{"status":"ok","timestamp":1650355618558,"user_tz":-120,"elapsed":332,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"outputs":[],"source":["class OpenDataset(torch.utils.data.Dataset):\n","  w, h = width, height\n","  def __init__(self, df, image_dir=IMAGE_ROOT):\n","    self.image_dir = image_dir\n","    self.files = glob.glob(self.image_dir+'/*')\n","    self.df = df\n","    self.image_infos = df['filename'].unique()\n","\n","  def __getitem__(self, ix):\n","\n","    #filename\tclass\txmin\txmax\tymin\tymax\n","\n","    # # load images and masks\n","    image_id = self.image_infos[ix]\n","    img_path = find(image_id, self.files)\n","    img = Image.open(img_path).convert('RGB')\n","    img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n","\n","    data = self.df[self.df['filename'] == image_id]\n","    labels = data['class'].values.tolist()\n","    data = data[['xmin','ymin','xmax','ymax']].values\n","    data[:,[0,2]] *= self.w\n","    data[:,[1,3]] *= self.h\n","    boxes = data.astype(np.uint32).tolist() # convert to absolute coordinates\n","    return img, boxes, labels\n","\n","  def collate_fn(self, batch):\n","    images, boxes, labels = [], [], []\n","    for item in batch:\n","      img, image_boxes, image_labels = item\n","      img = preprocess_image(img)[None]\n","      images.append(img)\n","      boxes.append(torch.tensor(image_boxes).float().to(device)/300.)\n","      labels.append(torch.tensor([label2target[c] for c in image_labels]).long().to(device))\n","    images = torch.cat(images).to(device)\n","    return images, boxes, labels\n","\n","  def __len__(self):\n","    return len(self.image_infos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_7ROj0gwIU1"},"outputs":[],"source":["if small_df:\n","  df_test = df_test[:50]"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"cHEx-uaWP_5G","executionInfo":{"status":"ok","timestamp":1650355821960,"user_tz":-120,"elapsed":1833,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"outputs":[],"source":["test_ds = OpenDataset(df_test)\n","test_loader = DataLoader(test_ds, batch_size=batch_size, collate_fn=test_ds.collate_fn, drop_last=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"tGiY3lyIFA4C","colab":{"base_uri":"https://localhost:8080/","height":171,"referenced_widgets":["18a868f93ac34ae888b0b256e7570ce3","44c2396614cd456499799beb4a75c559","4cc2e022968a499baec60fd9cd481a3c","2367468bb844401f8e0af628d6205b42","98b4fab4407b42cba0850d2171553aef","f47fc5b66f834469a88e6798d0f570c6","5f7f8e5c9adc4cd4af41f6440211b430","00043bdd8cba42cc943a611fd7da4649","d51e82ae25b64a59a8b648042f7a4cb5","04219602d441406aa43027101697f1e0","b609f7c8915d415db446e69772090196"]},"executionInfo":{"status":"ok","timestamp":1650355766725,"user_tz":-120,"elapsed":25978,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"dd90e131-7489-4cdb-bcac-17c2bbb6dcef"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a868f93ac34ae888b0b256e7570ce3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Loaded base model.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}],"source":["from model import SSD300, MultiBoxLoss\n","from detect import *\n","\n","# Load\n","model = SSD300(num_classes, device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy, device=device)\n","model.load_state_dict(torch.load(join(OUTPUT_MODELS, output_model_name), map_location=device))\n","# model.to(device);"]},{"cell_type":"code","source":["from torchvision.ops import nms\n","def decode_output(bbs, scores, labels):\n","  ixs = nms((torch.tensor(bbs)).type(torch.float64), torch.tensor(scores).type(torch.float64), 0.05)\n","  # bbs, scores, labels = [tensor[ixs] for tensor in [bbs, scores, labels]]\n","  bbs = [bb for i, bb in enumerate(bbs) if i in ixs]\n","  scores = [score for i, score in enumerate(scores) if i in ixs]\n","  labels = [label for i, label in enumerate(labels) if i in ixs]\n","  return bbs, scores, labels"],"metadata":{"id":"RTfwxdCN5HNw","executionInfo":{"status":"ok","timestamp":1650355766725,"user_tz":-120,"elapsed":12,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XCVKW0B_YKLN"},"source":["# Size Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":1738694,"status":"ok","timestamp":1650311092969,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"mVtlcTIPVaee","outputId":"41485ab5-5ded-4ada-b1d8-9ab65159a553"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\rProgress: |██████████████████████████████████████████████████| 100.0% Complete"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["bounding_boxes_detected = []\n","bounding_boxes_gt = []\n","n_items = len(test_loader)\n","out = display(IPython.display.Pretty('Starting'), display_id=True)\n","model.eval()\n","\n","for ix, (images, bbs, cls) in enumerate(test_loader):\n","  cls = cls[0]\n","  for i, box in enumerate(bbs[0]):\n","    cls_box = target2label[int(cls[i])]\n","    box = (box * width).type(torch.int64).tolist()\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls_box,\n","      coordinates       = list(box),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    bounding_boxes_gt.append(bb)\n","\n","  image = Image.fromarray(np.uint8(images[0].cpu().permute(1, 2, 0).numpy() * 255))\n","  bbs, labels, scores = detect(image, model, min_score=0.0, max_overlap=0.05,top_k=200, device=device)\n","  bbs, scores, labels = decode_output(bbs, scores, labels.tolist())\n","\n","  #Detected\n","  for i, box in enumerate(bbs):\n","    cls_box = target2label[int(labels[i])]\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls_box,\n","      coordinates       = box,\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.DETECTED,\n","      confidence        = scores[i],\n","      format            = BBFormat.XYX2Y2\n","    )\n","    bounding_boxes_detected.append(bb)\n","\n","  printProgressBar(ix + 1, n_items, prefix = 'Progress:', suffix = 'Complete', length = 50)"]},{"cell_type":"markdown","metadata":{"id":"oOW8t1uOU9UG"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56949,"status":"ok","timestamp":1650311153901,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"-Cafjb_keoRd","outputId":"9c49593b-65f3-4776-825d-19851594f86d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AP': 0.3241587786954479,\n"," 'AP50': 0.5751419079669917,\n"," 'AP75': 0.3317989507108984,\n"," 'APlarge': 0.607574792916418,\n"," 'APmedium': 0.49865651600497796,\n"," 'APsmall': 0.1689894609957411,\n"," 'AR1': 0.3546600851614429,\n"," 'AR10': 0.3952168226508288,\n"," 'AR100': 0.3956214017113159,\n"," 'ARlarge': 0.6758517302407899,\n"," 'ARmedium': 0.5853984414278532,\n"," 'ARsmall': 0.23067560781146454}"]},"metadata":{},"execution_count":182}],"source":["coco_evaluator.get_coco_summary(\n","    groundtruth_bbs = bounding_boxes_gt,\n","    detected_bbs = bounding_boxes_detected,\n","    small_size = 146,\n","    medium_size = 228\n",")"]},{"cell_type":"markdown","metadata":{"id":"-XplV_SmU4a1"},"source":["# Full COCO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1650311208159,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"jMpnwblAvg0r","outputId":"2737cddf-e6b8-4327-bf2f-4267d34b682a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                      Bus  \\\n","class                                                                 Bus   \n","precision               [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n","recall                  [0.00043233895373973193, 0.0008646779074794639...   \n","AP                                                               0.616386   \n","interpolated precision  [1.0, 1.0, 1.0, 1.0, 0.9928571428571429, 0.992...   \n","\n","                                                                    Truck  \n","class                                                               Truck  \n","precision               [0.0, 0.0, 0.3333333333333333, 0.5, 0.6, 0.666...  \n","recall                  [0.0, 0.0, 0.0003996802557953637, 0.0007993605...  \n","AP                                                               0.533898  \n","interpolated precision  [0.9836065573770492, 0.9836065573770492, 0.983...  "],"text/html":["\n","  <div id=\"df-052aca6b-d7ff-4500-b884-3405a2d28369\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Bus</th>\n","      <th>Truck</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>class</th>\n","      <td>Bus</td>\n","      <td>Truck</td>\n","    </tr>\n","    <tr>\n","      <th>precision</th>\n","      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n","      <td>[0.0, 0.0, 0.3333333333333333, 0.5, 0.6, 0.666...</td>\n","    </tr>\n","    <tr>\n","      <th>recall</th>\n","      <td>[0.00043233895373973193, 0.0008646779074794639...</td>\n","      <td>[0.0, 0.0, 0.0003996802557953637, 0.0007993605...</td>\n","    </tr>\n","    <tr>\n","      <th>AP</th>\n","      <td>0.616386</td>\n","      <td>0.533898</td>\n","    </tr>\n","    <tr>\n","      <th>interpolated precision</th>\n","      <td>[1.0, 1.0, 1.0, 1.0, 0.9928571428571429, 0.992...</td>\n","      <td>[0.9836065573770492, 0.9836065573770492, 0.983...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-052aca6b-d7ff-4500-b884-3405a2d28369')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-052aca6b-d7ff-4500-b884-3405a2d28369 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-052aca6b-d7ff-4500-b884-3405a2d28369');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":185}],"source":["df = coco_evaluator.get_coco_metrics(\n","        bounding_boxes_gt,\n","        bounding_boxes_detected,\n","        iou_threshold=0.5,\n","        area_range=(0, np.inf),\n","        max_dets=100,\n",")\n","df = pd.DataFrame.from_dict(df)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"TOVY3AZhU1f0"},"source":["# PASCAL VOL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":817629,"status":"ok","timestamp":1650312185377,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"umuNe92_sDXL","outputId":"554b94af-66aa-4107-a167-207b6f910ee5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               per_class       mAP\n","Bus    {'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...  0.684875\n","Truck  {'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...  0.684875"],"text/html":["\n","  <div id=\"df-87e03965-0e37-49e0-8f44-7aec51632b07\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>per_class</th>\n","      <th>mAP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Bus</th>\n","      <td>{'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...</td>\n","      <td>0.684875</td>\n","    </tr>\n","    <tr>\n","      <th>Truck</th>\n","      <td>{'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1...</td>\n","      <td>0.684875</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87e03965-0e37-49e0-8f44-7aec51632b07')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-87e03965-0e37-49e0-8f44-7aec51632b07 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-87e03965-0e37-49e0-8f44-7aec51632b07');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":186}],"source":["df = pascal_voc_evaluator.get_pascalvoc_metrics(\n","    bounding_boxes_gt,\n","    bounding_boxes_detected,\n","    iou_threshold= 0.1,\n","    method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION\n",")\n","\n","df = pd.DataFrame.from_dict(df)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"RnM0quJQYHJp"},"source":["# Color Analysis"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1650355766726,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"bTgNQN5mVRpP"},"outputs":[],"source":["def image_light(img, thrshld = 127):\n","  if type(img) is torch.Tensor:\n","    img = img.cpu().permute(1,2,0).numpy()\n","  rgb = img * 255\n","  rgb = np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n","  \n","  is_light = np.mean(rgb) > thrshld\n","\n","  # Light: 0\n","  # Dark: 1\n","\n","  # return 0 if is_light else 1\n","  return {'value': np.mean(rgb),\n","          'brightness': 'light' if is_light else 'dark'\n","          }\n","\n","def avg_img_color(img):\n","  if type(img) is torch.Tensor:\n","    img = img.cpu().permute(1,2,0).numpy()\n","  rgb_avg = img.mean(axis=(0, 1)) \n","  hsv_avg = rgb2hsv(img).mean(axis=(0, 1))\n","  luv_avg = rgb2luv(img).mean(axis=(0, 1))\n","  lab_avg = rgb2lab(img).mean(axis=(0, 1))\n","\n","  return {\n","    'rgb_avg_r': float(rgb_avg[0]),\n","    'rgb_avg_g': float(rgb_avg[1]),\n","    'rgb_avg_b': float(rgb_avg[2]),\n","    'hsv_avg_h': float(hsv_avg[0]),\n","    'hsv_avg_s': float(hsv_avg[1]),\n","    'hsv_avg_v': float(hsv_avg[2])\n","  }\n","\n","def get_sharpness(img):\n","  if type(img) is torch.Tensor:\n","    img = img.cpu().permute(1,2,0).numpy()\n","  i = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n","\n","  gy, gx = np.gradient(i)\n","  gnorm = np.sqrt(gx**2 + gy**2)\n","  sharpness = np.average(gnorm)\n","  return sharpness"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650355766726,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"Nl0iDKb_VRmH"},"outputs":[],"source":["def bb_intersection_over_union(boxA, boxB):\n","\n","  # xA = max(boxA[0], boxB[0])\n","  # yA = max(boxA[1], boxB[1])\n","  # xB = min(boxA[2], boxB[2])\n","  # yB = min(boxA[3], boxB[3])\n","\n","  # interArea = (xB - xA) * (yB - yA)\n","\n","  # boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n","  # boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n","\n","  # iou = interArea / float(boxAArea + boxBArea - interArea)\n","  iou = bops.box_iou(torch.tensor([boxA]), torch.tensor([boxB]))\n","  return iou.item()\n","\n","\n","def detected(preds, gt, iou_threshold ):\n","  det = False\n","  max_conf = 0\n","  for i, pred in enumerate(preds):\n","    if pred[0] == gt[0]:\n","      if pred[1] == gt[1]:\n","        iuo = bb_intersection_over_union(pred[-4:], gt[-4:])\n","        if iuo >= iou_threshold:\n","          det = True\n","          if pred[2] > max_conf:\n","            max_conf = pred[2]\n","\n","  return det, max_conf"]},{"cell_type":"code","source":["blur_filter = 1/9 *  torch.tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n","metadata = []\n","n_items = len(test_loader)\n","out = display(IPython.display.Pretty('Starting'), display_id=True)\n","model.eval()\n","\n","for ix, (images, bbs, cls) in enumerate(test_loader):\n","  \n","  cls_gt = cls[0]\n","  img = images[0]\n","  img_ = Image.fromarray(np.uint8(img.cpu().permute(1, 2, 0).numpy() * 255))\n","\n","\n","  # plain image\n","  c_img = image_light(img)\n","  c_avg_img = avg_img_color(img)\n","\n","  preds = []\n","  \n","  # image = Image.fromarray(np.uint8(img_.numpy() * 255))\n","  bbs_output, labels_output, scores_output = detect(img_, model, min_score=0.01, max_overlap=0.05,top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'standard',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","###########################################################################################\n","\n","  # blurred image\n","  blurred_img = cv2.filter2D(img.cpu().permute(1, 2, 0).numpy(), -1, kernel = blur_filter.numpy())\n","  c_img = image_light(blurred_img)\n","  c_avg_img = avg_img_color(blurred_img)\n","\n","  blurred_imgs = [torch.from_numpy(blurred_img).permute(2, 0, 1)]\n","  blurred_img = blurred_imgs[0]\n","  blurred_img_ = Image.fromarray(np.uint8(blurred_img.cpu().permute(1, 2, 0).numpy() * 255))\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(blurred_img_, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = blurred_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'blurred',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","\n","###########################################################################################\n","\n","  # noisy image\n","\n","  noise_img = random_noise(img.cpu().permute(1, 2, 0).numpy(), mode='s&p',amount=0.05)\n","  c_img = image_light(noise_img)\n","  c_avg_img = avg_img_color(noise_img)\n","\n","  noisy_imgs = [torch.from_numpy(noise_img).permute(2, 0, 1)]\n","  noisy_imgs = [torch.tensor(im).type(torch.FloatTensor).to(device) for im in noisy_imgs]\n","  noisy_img = noisy_imgs[0]\n","  noisy_img_ = Image.fromarray(np.uint8(blurred_img.cpu().permute(1, 2, 0).numpy() * 255))\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(noisy_img_, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = noisy_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'noisy',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","\n","###########################################################################################\n","\n","  # bright image\n","\n","  new_image = PIL.ImageEnhance.Brightness(img_).enhance(2)\n","  bright_image = np.array(new_image) / 255\n","  bright_imgs = [torch.from_numpy(bright_image).permute(2, 0, 1)]\n","  bright_imgs = [torch.tensor(im).type(torch.FloatTensor).to(device) for im in bright_imgs]\n","  bright_img = bright_imgs[0]\n","\n","  c_img = image_light(bright_image)\n","  c_avg_img = avg_img_color(bright_image)\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(new_image, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = bright_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'bright',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","\n","\n","\n","###########################################################################################\n","\n","  # contrast image\n","\n","  new_image = PIL.ImageEnhance.Contrast(img_).enhance(2)\n","  contrast_image = np.array(new_image) / 255\n","  contrast_imgs = [torch.from_numpy(contrast_image).permute(2, 0, 1)]\n","  contrast_imgs = [torch.tensor(im).type(torch.FloatTensor).to(device) for im in contrast_imgs]\n","  contrast_img = contrast_imgs[0]\n","\n","  c_img = image_light(contrast_image)\n","  c_avg_img = avg_img_color(contrast_image)\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(new_image, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = contrast_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'contrast',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","\n","\n","###########################################################################################\n","\n","  # sharp image\n","\n","  new_image = PIL.ImageEnhance.Sharpness(img_).enhance(3)\n","  sharp_image = np.array(new_image) / 255\n","  sharp_imgs = [torch.from_numpy(sharp_image).permute(2, 0, 1)]\n","  sharp_imgs = [torch.tensor(im).type(torch.FloatTensor).to(device) for im in sharp_imgs]\n","  sharp_img = sharp_imgs[0]\n","\n","  c_img = image_light(sharp_image)\n","  c_avg_img = avg_img_color(sharp_image)\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(new_image, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = sharp_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'sharp',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","    \n","\n","###########################################################################################\n","\n","  # dark image\n","\n","  new_image = PIL.ImageEnhance.Brightness(img_).enhance(0.4)\n","  dark_image = np.array(new_image) / 255\n","  dark_imgs = [torch.from_numpy(dark_image).permute(2, 0, 1)]\n","  dark_imgs = [torch.tensor(im).type(torch.FloatTensor).to(device) for im in dark_imgs]\n","  dark_img = dark_imgs[0]\n","\n","  c_img = image_light(dark_image)\n","  c_avg_img = avg_img_color(dark_image)\n","  \n","  preds = []\n","  \n","  bbs_output, labels_output, scores_output = detect(new_image, model, min_score=0.01, max_overlap=0.05, top_k=200, device=device)\n","  bbs_output, scores_output, labels_output = decode_output(bbs_output, scores_output, labels_output.tolist())\n","\n","  for i_bb, bb in enumerate(bbs_output):\n","    X1, Y1, X2, Y2 = bb\n","    l = target2label[labels_output[i_bb]]\n","    preds.append([ix, l, scores_output[i_bb], X1, Y1, X2, Y2])\n","\n","  for i, box in enumerate(bbs[0]):\n","    \n","    box_gt = (box * width).type(torch.int64).tolist()\n","    X1, Y1, X2, Y2 = box_gt\n","      \n","    cls_ = target2label[int(cls_gt[i])]\n","\n","    # object frame\n","    obj_frame = dark_img[:3, Y1:Y2, X1:X2]\n","\n","    # colors\n","    c_obj = image_light(obj_frame)\n","    c_avg_obj = avg_img_color(obj_frame)\n","\n","    # Area\n","    bb = BoundingBox(\n","      image_name        = str(ix),\n","      class_id          = cls,\n","      coordinates       = list(box_gt),\n","      type_coordinates  = CoordinatesType.ABSOLUTE,\n","      bb_type           = BBType.GROUND_TRUTH,\n","      confidence        = None,\n","      format            = BBFormat.XYX2Y2\n","    )\n","    \n","    # detected\n","    det, conf = detected(\n","        preds,\n","        [ix, cls_, 1, X1, Y1, X2, Y2],\n","        0.6\n","    )\n","\n","    metadata.append({'image_id': ix,\n","                    'image_version': 'dark',\n","                    'image_brightness_value': c_img['value'],\n","                    'image_brightness_interpretation': c_img['brightness'],\n","                    'image_rgb_avg_r': c_avg_img['rgb_avg_r'],\n","                    'image_rgb_avg_g': c_avg_img['rgb_avg_g'],\n","                    'image_rgb_avg_b': c_avg_img['rgb_avg_b'],\n","                    'image_hsv_avg_h': c_avg_img['hsv_avg_h'],\n","                    'image_hsv_avg_s': c_avg_img['hsv_avg_s'],\n","                    'image_hsv_avg_v': c_avg_img['hsv_avg_v'],\n","                    'object_brightness_value': c_obj['value'],\n","                    'object_brightness_interpretation': c_obj['brightness'],\n","                    'object_rgb_avg_r': c_avg_obj['rgb_avg_r'],\n","                    'object_rgb_avg_g': c_avg_obj['rgb_avg_g'],\n","                    'object_rgb_avg_b': c_avg_obj['rgb_avg_b'],\n","                    'object_hsv_avg_h': c_avg_obj['hsv_avg_h'],\n","                    'object_hsv_avg_s': c_avg_obj['hsv_avg_s'],\n","                    'object_hsv_avg_v': c_avg_obj['hsv_avg_v'],\n","                    'detected': det,\n","                    'confidence': conf,\n","                    'object_size': bb.get_area(),\n","                    'object_class': cls_\n","                   }\n","                  )\n","  printProgressBar(ix + 1, n_items, prefix = 'Progress:', suffix = 'Complete', length = 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"GKWnCpkVXu_6","outputId":"2232c5a3-c10a-4f45-f185-6256e793aa52","executionInfo":{"status":"ok","timestamp":1650359474426,"user_tz":-120,"elapsed":3641245,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}}},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["\rProgress: |██████████████████████████████████████████████████| 100.0% Complete"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:414: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:495: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["# show(img)\n","# show(blurred_img)\n","# show(noise_img)\n","# show(bright_img)\n","# show(contrast_img)\n","# show(sharp_img)\n","# show(dark_img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WbksEelOAwLjZrKyZbT4Px9EwSgg00mx"},"id":"KnguKY2f7VSl","executionInfo":{"status":"ok","timestamp":1650324293771,"user_tz":-120,"elapsed":17161,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"03410c47-df0e-4431-f8a1-a09c38295ebf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"executionInfo":{"elapsed":21665,"status":"ok","timestamp":1650359561940,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"},"user_tz":-120},"id":"BAvFYUomVRgl","outputId":"f09368ef-8a80-4a1e-826e-f41ec90d5e0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       image_id image_version  image_brightness_value  \\\n","33698      3044        bright              134.776908   \n","33699      3044      contrast               95.425101   \n","33700      3044      contrast               95.425101   \n","33701      3044         sharp               82.461668   \n","33702      3044         sharp               82.461668   \n","33703      3044          dark               32.575656   \n","33704      3044          dark               32.575656   \n","\n","      image_brightness_interpretation  image_rgb_avg_r  image_rgb_avg_g  \\\n","33698                           light         0.552707         0.519490   \n","33699                            dark         0.405319         0.362328   \n","33700                            dark         0.405319         0.362328   \n","33701                            dark         0.343913         0.316154   \n","33702                            dark         0.343913         0.316154   \n","33703                            dark         0.136002         0.124840   \n","33704                            dark         0.136002         0.124840   \n","\n","       image_rgb_avg_b  image_hsv_avg_h  image_hsv_avg_s  image_hsv_avg_v  \\\n","33698         0.512211         0.254606         0.208871         0.568104   \n","33699         0.354209         0.183127         0.219872         0.419370   \n","33700         0.354209         0.183127         0.219872         0.419370   \n","33701         0.307026         0.338734         0.255500         0.356855   \n","33702         0.307026         0.338734         0.255500         0.356855   \n","33703         0.121187         0.313693         0.260449         0.140653   \n","33704         0.121187         0.313693         0.260449         0.140653   \n","\n","       object_brightness_value object_brightness_interpretation  \\\n","33698               219.471943                            light   \n","33699               198.343621                            light   \n","33700               175.065043                            light   \n","33701               151.929901                            light   \n","33702               137.296597                            light   \n","33703                60.404664                             dark   \n","33704                54.514213                             dark   \n","\n","       object_rgb_avg_r  object_rgb_avg_g  object_rgb_avg_b  object_hsv_avg_h  \\\n","33698          0.900724          0.844611          0.839133          0.215730   \n","33699          0.790550          0.769863          0.786081          0.294754   \n","33700          0.755075          0.657424          0.657277          0.318293   \n","33701          0.607832          0.591539          0.586746          0.379261   \n","33702          0.574613          0.523310          0.521784          0.416595   \n","33703          0.241760          0.235164          0.233139          0.361929   \n","33704          0.228268          0.207731          0.207138          0.402688   \n","\n","       object_hsv_avg_s  object_hsv_avg_v  detected  confidence  object_size  \\\n","33698          0.116299          0.918348     False    0.000000      10486.0   \n","33699          0.135345          0.818334     False    0.000000       2240.0   \n","33700          0.271466          0.785582     False    0.000000      10486.0   \n","33701          0.131465          0.630860     False    0.000000       2240.0   \n","33702          0.209666          0.603817      True    0.969661      10486.0   \n","33703          0.113127          0.249445     False    0.000000       2240.0   \n","33704          0.190001          0.238191      True    0.989545      10486.0   \n","\n","      object_class  \n","33698          Bus  \n","33699          Bus  \n","33700          Bus  \n","33701          Bus  \n","33702          Bus  \n","33703          Bus  \n","33704          Bus  "],"text/html":["\n","  <div id=\"df-662c01fe-769d-45f0-bb1d-7c0f0bb14800\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>image_version</th>\n","      <th>image_brightness_value</th>\n","      <th>image_brightness_interpretation</th>\n","      <th>image_rgb_avg_r</th>\n","      <th>image_rgb_avg_g</th>\n","      <th>image_rgb_avg_b</th>\n","      <th>image_hsv_avg_h</th>\n","      <th>image_hsv_avg_s</th>\n","      <th>image_hsv_avg_v</th>\n","      <th>object_brightness_value</th>\n","      <th>object_brightness_interpretation</th>\n","      <th>object_rgb_avg_r</th>\n","      <th>object_rgb_avg_g</th>\n","      <th>object_rgb_avg_b</th>\n","      <th>object_hsv_avg_h</th>\n","      <th>object_hsv_avg_s</th>\n","      <th>object_hsv_avg_v</th>\n","      <th>detected</th>\n","      <th>confidence</th>\n","      <th>object_size</th>\n","      <th>object_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>33698</th>\n","      <td>3044</td>\n","      <td>bright</td>\n","      <td>134.776908</td>\n","      <td>light</td>\n","      <td>0.552707</td>\n","      <td>0.519490</td>\n","      <td>0.512211</td>\n","      <td>0.254606</td>\n","      <td>0.208871</td>\n","      <td>0.568104</td>\n","      <td>219.471943</td>\n","      <td>light</td>\n","      <td>0.900724</td>\n","      <td>0.844611</td>\n","      <td>0.839133</td>\n","      <td>0.215730</td>\n","      <td>0.116299</td>\n","      <td>0.918348</td>\n","      <td>False</td>\n","      <td>0.000000</td>\n","      <td>10486.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33699</th>\n","      <td>3044</td>\n","      <td>contrast</td>\n","      <td>95.425101</td>\n","      <td>dark</td>\n","      <td>0.405319</td>\n","      <td>0.362328</td>\n","      <td>0.354209</td>\n","      <td>0.183127</td>\n","      <td>0.219872</td>\n","      <td>0.419370</td>\n","      <td>198.343621</td>\n","      <td>light</td>\n","      <td>0.790550</td>\n","      <td>0.769863</td>\n","      <td>0.786081</td>\n","      <td>0.294754</td>\n","      <td>0.135345</td>\n","      <td>0.818334</td>\n","      <td>False</td>\n","      <td>0.000000</td>\n","      <td>2240.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33700</th>\n","      <td>3044</td>\n","      <td>contrast</td>\n","      <td>95.425101</td>\n","      <td>dark</td>\n","      <td>0.405319</td>\n","      <td>0.362328</td>\n","      <td>0.354209</td>\n","      <td>0.183127</td>\n","      <td>0.219872</td>\n","      <td>0.419370</td>\n","      <td>175.065043</td>\n","      <td>light</td>\n","      <td>0.755075</td>\n","      <td>0.657424</td>\n","      <td>0.657277</td>\n","      <td>0.318293</td>\n","      <td>0.271466</td>\n","      <td>0.785582</td>\n","      <td>False</td>\n","      <td>0.000000</td>\n","      <td>10486.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33701</th>\n","      <td>3044</td>\n","      <td>sharp</td>\n","      <td>82.461668</td>\n","      <td>dark</td>\n","      <td>0.343913</td>\n","      <td>0.316154</td>\n","      <td>0.307026</td>\n","      <td>0.338734</td>\n","      <td>0.255500</td>\n","      <td>0.356855</td>\n","      <td>151.929901</td>\n","      <td>light</td>\n","      <td>0.607832</td>\n","      <td>0.591539</td>\n","      <td>0.586746</td>\n","      <td>0.379261</td>\n","      <td>0.131465</td>\n","      <td>0.630860</td>\n","      <td>False</td>\n","      <td>0.000000</td>\n","      <td>2240.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33702</th>\n","      <td>3044</td>\n","      <td>sharp</td>\n","      <td>82.461668</td>\n","      <td>dark</td>\n","      <td>0.343913</td>\n","      <td>0.316154</td>\n","      <td>0.307026</td>\n","      <td>0.338734</td>\n","      <td>0.255500</td>\n","      <td>0.356855</td>\n","      <td>137.296597</td>\n","      <td>light</td>\n","      <td>0.574613</td>\n","      <td>0.523310</td>\n","      <td>0.521784</td>\n","      <td>0.416595</td>\n","      <td>0.209666</td>\n","      <td>0.603817</td>\n","      <td>True</td>\n","      <td>0.969661</td>\n","      <td>10486.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33703</th>\n","      <td>3044</td>\n","      <td>dark</td>\n","      <td>32.575656</td>\n","      <td>dark</td>\n","      <td>0.136002</td>\n","      <td>0.124840</td>\n","      <td>0.121187</td>\n","      <td>0.313693</td>\n","      <td>0.260449</td>\n","      <td>0.140653</td>\n","      <td>60.404664</td>\n","      <td>dark</td>\n","      <td>0.241760</td>\n","      <td>0.235164</td>\n","      <td>0.233139</td>\n","      <td>0.361929</td>\n","      <td>0.113127</td>\n","      <td>0.249445</td>\n","      <td>False</td>\n","      <td>0.000000</td>\n","      <td>2240.0</td>\n","      <td>Bus</td>\n","    </tr>\n","    <tr>\n","      <th>33704</th>\n","      <td>3044</td>\n","      <td>dark</td>\n","      <td>32.575656</td>\n","      <td>dark</td>\n","      <td>0.136002</td>\n","      <td>0.124840</td>\n","      <td>0.121187</td>\n","      <td>0.313693</td>\n","      <td>0.260449</td>\n","      <td>0.140653</td>\n","      <td>54.514213</td>\n","      <td>dark</td>\n","      <td>0.228268</td>\n","      <td>0.207731</td>\n","      <td>0.207138</td>\n","      <td>0.402688</td>\n","      <td>0.190001</td>\n","      <td>0.238191</td>\n","      <td>True</td>\n","      <td>0.989545</td>\n","      <td>10486.0</td>\n","      <td>Bus</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-662c01fe-769d-45f0-bb1d-7c0f0bb14800')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-662c01fe-769d-45f0-bb1d-7c0f0bb14800 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-662c01fe-769d-45f0-bb1d-7c0f0bb14800');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["df = pd.DataFrame.from_dict(metadata)\n","df.to_excel(join(OUTPUT_REPORTS, output_testing_report))\n","df.tail(7)"]},{"cell_type":"code","source":["df.head(7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"hu21OmXaLEGd","executionInfo":{"status":"error","timestamp":1650365781425,"user_tz":-120,"elapsed":900,"user":{"displayName":"Bastian B.","userId":"10033977703569380654"}},"outputId":"c5505f7f-510f-481e-f179-20111b17a687"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5f9735024a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Testing_SSD_VGG16.ipynb","provenance":[],"authorship_tag":"ABX9TyNYAnefvi16kxyu9SiDuB6f"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"18a868f93ac34ae888b0b256e7570ce3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44c2396614cd456499799beb4a75c559","IPY_MODEL_4cc2e022968a499baec60fd9cd481a3c","IPY_MODEL_2367468bb844401f8e0af628d6205b42"],"layout":"IPY_MODEL_98b4fab4407b42cba0850d2171553aef"}},"44c2396614cd456499799beb4a75c559":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f47fc5b66f834469a88e6798d0f570c6","placeholder":"​","style":"IPY_MODEL_5f7f8e5c9adc4cd4af41f6440211b430","value":"100%"}},"4cc2e022968a499baec60fd9cd481a3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00043bdd8cba42cc943a611fd7da4649","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d51e82ae25b64a59a8b648042f7a4cb5","value":553433881}},"2367468bb844401f8e0af628d6205b42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04219602d441406aa43027101697f1e0","placeholder":"​","style":"IPY_MODEL_b609f7c8915d415db446e69772090196","value":" 528M/528M [00:08&lt;00:00, 77.0MB/s]"}},"98b4fab4407b42cba0850d2171553aef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47fc5b66f834469a88e6798d0f570c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f7f8e5c9adc4cd4af41f6440211b430":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00043bdd8cba42cc943a611fd7da4649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d51e82ae25b64a59a8b648042f7a4cb5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04219602d441406aa43027101697f1e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b609f7c8915d415db446e69772090196":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}